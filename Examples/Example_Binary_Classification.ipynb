{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through a simple binary classification example, explaining library functionality along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ABCD_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define directory with the 2.0_NDA_Data\n",
    "nda_dr = '/mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/'\n",
    "\n",
    "#This file stores the name mapping\n",
    "test_mapping_loc = nda_dr + 'ABCD_Release_ Notes_Data_Release_ 2.0/22. ABCD_Release_2.0_mapping_r.csv'\n",
    "\n",
    "#We will use as the neuroimaging data just the sMRI data\n",
    "test_data_loc1 = nda_dr + 'MRI/ABCD sMRI Part 1.csv'\n",
    "test_data_loc2 = nda_dr + 'MRI/ABCD sMRI Part 2.csv'\n",
    "\n",
    "#We will load target data (and covariate data) from here\n",
    "test_target_loc = nda_dr + 'Mental Health/ABCD Parent Demographics Survey.csv'\n",
    "\n",
    "#We will load stratification data from here\n",
    "test_strat_loc = nda_dr + 'Other Non-Imaging/ABCD ACS Post Stratification Weights.csv'\n",
    "\n",
    "#We will load exclusions from here, it is the list of flipped subject ids\n",
    "test_exclusion_loc = '/home/sage/bader_things/invalid_pguids.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the class object, which we will use to load load and to train/test different ML models.\n",
    "There are a few global parameters which we can optionally set when defining this object as well, lets look and see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module ABCD_ML.ABCD_ML:\n",
      "\n",
      "__init__(self, eventname='baseline_year_1_arm_1', use_default_subject_ids=True, default_na_values=['777', '999'], original_targets_key='targets', low_memory_mode=False, random_state=None, verbose=True)\n",
      "    Main class init\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    eventname : str or None, optional\n",
      "        Optional value to provide, specifying to keep certain rows\n",
      "        when reading data based on the eventname flag.\n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "        (default = baseline_year_1_arm_1)\n",
      "    \n",
      "    use_default_subject_ids : bool, optional\n",
      "        Flag to determine the usage of 'default' subject id behavior.\n",
      "        If set to True, this will convert input NDAR subject ids\n",
      "        into upper case, with prepended NDAR_ - type format.\n",
      "        If set to False, then all input subject names must be entered\n",
      "        explicitly the same, no preprocessing will be done on them.\n",
      "        (default = True)\n",
      "    \n",
      "    default_na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values.\n",
      "        (default = ['777', '999'])\n",
      "    \n",
      "    original_targets_key : str, optional\n",
      "        This parameter refers to the column name / key, that the\n",
      "        target variable of interest will be stored under. There are not a\n",
      "        lot of reasons to change this setting, except in the case of\n",
      "        a naming conflict - or just for further customization.\n",
      "        (default = 'targets')\n",
      "    \n",
      "    low_memory_mode : bool, optional\n",
      "        This parameter dictates behavior around loading in data,\n",
      "        specifically, if `low_memory_mode` is set to True,\n",
      "        then when loading data from multiple sources, only common\n",
      "        subjects will be saved as each data source is loaded.\n",
      "        For comparison, when low memory mode if off, the dropping\n",
      "        of non-common subjects occurs later. Though regardless of if low\n",
      "        memory mode is on or off, subjects will be dropped right away\n",
      "        when exclusions or strat is loaded. Non low memory mode\n",
      "        behavior is useful when the user wants to try loading different\n",
      "        data, and doesn't want automatic drops to occur.\n",
      "        If set to True, individual dataframes self.data, self.covars ect...\n",
      "        will also be deleted from memory as soon as modeling begins.\n",
      "        (default = False)\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional\n",
      "        Random state, either as int for a specific seed, or if None then\n",
      "        the random seed is set by np.random.\n",
      "        (default = None)\n",
      "    \n",
      "    verbose: bool, optional\n",
      "        If set to true will display diagnostic and other output during\n",
      "        dataloading and model training ect... if set to False this output\n",
      "        will be muted.\n",
      "        (default = True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ABCD_ML.ABCD_ML.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the default parameters are okay for this simple example, but any of them can be changed. Let's change n_jobs to 4 instead of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD_ML object initialized\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML.ABCD_ML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue by optionally loading in a name map, which is simply a dictionary that attempts to rename any column names loaded in, if those column names are a key in the dictionary. This is useful for ABCD data as the default column names might not be useful.\n",
    "\n",
    "Note this name map and these parameters are for the 'ABCD 2.0 Explorer' formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded map file\n"
     ]
    }
   ],
   "source": [
    "ML.load_name_map(loc = test_mapping_loc,\n",
    "                 source_name_col = \"NDAR name\",\n",
    "                 target_name_col = \"REDCap name/NDA alias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what exactly is in this dictionary if we want to confirm we loaded it correctly.\n",
    "It is loaded as name_map within the ABCD_ML class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ddtidp_674': 'dmri_dtifagm_cortdestrieux_ssuborbitallh',\n",
       " 'ddtidp_748': 'dmri_dtifagm_cortdestrieux_ssuborbitalrh',\n",
       " 'ddtidp_675': 'dmri_dtifagm_cortdestrieux_ssubparietallh',\n",
       " 'ddtidp_749': 'dmri_dtifagm_cortdestrieux_ssubparietalrh',\n",
       " 'ddtidp_676': 'dmri_dtifagm_cortdestrieux_stemporalinflh',\n",
       " 'ddtidp_750': 'dmri_dtifagm_cortdestrieux_stemporalinfrh',\n",
       " 'ddtidp_677': 'dmri_dtifagm_cortdestrieux_stemporalsuplh',\n",
       " 'ddtidp_751': 'dmri_dtifagm_cortdestrieux_stemporalsuprh',\n",
       " 'ddtidp_678': 'dmri_dtifagm_cortdestrieux_stemporaltransverselh',\n",
       " 'ddtidp_752': 'dmri_dtifagm_cortdestrieux_stemporaltransverserh',\n",
       " 'dmri_dtifagwc_cdsn_bslh': 'dmri_dtifagwc_cortdesikan_banksstslh',\n",
       " 'dmri_dtifagwc_cdsn_bsrh': 'dmri_dtifagwc_cortdesikan_banksstsrh',\n",
       " 'dmri_dtifagwc_cdsn_cdacatelh': 'dmri_dtifagwc_cortdesikan_caudalanteriorcingulatelh',\n",
       " 'dmri_dtifagwc_cdsn_cdacaterh': 'dmri_dtifagwc_cortdesikan_caudalanteriorcingulaterh',\n",
       " 'dmri_dtifagwc_cdsn_cdmflh': 'dmri_dtifagwc_cortdesikan_caudalmiddlefrontallh',\n",
       " 'dmri_dtifagwc_cdsn_cdmfrh': 'dmri_dtifagwc_cortdesikan_caudalmiddlefrontalrh',\n",
       " 'dmri_dtifagwc_cdsn_cuneuslh': 'dmri_dtifagwc_cortdesikan_cuneuslh',\n",
       " 'dmri_dtifagwc_cdsn_cuneusrh': 'dmri_dtifagwc_cortdesikan_cuneusrh',\n",
       " 'dmri_dtifagwc_cdsn_ehinallh': 'dmri_dtifagwc_cortdesikan_entorhinallh',\n",
       " 'dmri_dtifagwc_cdsn_ehinalrh': 'dmri_dtifagwc_cortdesikan_entorhinalrh'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_examples = {k: ML.name_map[k] for k in list(ML.name_map)[300:320]}\n",
    "some_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load in the actual data. Like before we can check what parameters this function wants / can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_data in module ABCD_ML._Data:\n",
      "\n",
      "load_data(loc, dataset_type, drop_keys=[], filter_outlier_percent=None, winsorize_val=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Load a ABCD2p0NDA (default) or 2.0_ABCD_Data_Explorer (explorer)\n",
      "    release formatted neuroimaging dataset - of derived ROI level info.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or list of\n",
      "        The location of the csv file to load data load from.\n",
      "        If passed a list, then will load each loc in the list,\n",
      "        and will assume them all to be of the same dataset_type if one\n",
      "        dataset_type is passed, or if they differ in type, a list must be\n",
      "        passed to dataset_type with the different types in order.\n",
      "        Note: some proc will be done on each loaded dataset before merging\n",
      "        with the rest (duplicate subjects, proc for eventname ect...), but\n",
      "        other dataset loading behavior won't occur until after the merge,\n",
      "        e.g., dropping cols by key, filtering for outlier, ect...\n",
      "    \n",
      "    dataset_type : {'default', 'explorer', 'custom'} or list of, optional\n",
      "        The type of dataset to load from. If a list is passed, then loc must\n",
      "        also be a list, and the indices should correspond.\n",
      "        Likewise, if loc is a list and dataset_type is not,\n",
      "        it is assumed all datasets are the same type.\n",
      "        Where each dataset type is,\n",
      "    \n",
      "        - 'default' : ABCD2p0NDA style, (.txt and tab seperated)\n",
      "            The 4 columns before 'src_subject_id' and the 4 after,\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'explorer' : 2.0_ABCD_Data_Explorer tyle (.csv and comma seperated)\n",
      "            The first 2 columns before 'src_subject_id'\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom' : A user-defined custom dataset. Right now this is only\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called 'src_subject_id'. No columns will be dropped,\n",
      "            unless specific drop keys are passed.\n",
      "    \n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_keys : list, optional\n",
      "        A list of keys to drop columns by, where if any key given in a columns\n",
      "        name, then that column will be dropped.\n",
      "        (Note: if a name mapping exists, this drop step will be\n",
      "        conducted after renaming)\n",
      "        (default = [])\n",
      "    \n",
      "    filter_outlier_percent : int, float, tuple or None, optional\n",
      "        For float / ordinal data only.\n",
      "        A percent of values to exclude from either end of the\n",
      "        targets distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_outlier_percent` to None for no filtering.\n",
      "        (default = None)\n",
      "        If over 1 then treated as a percent, if under 1, then\n",
      "        used directly.\n",
      "    \n",
      "    winsorize_val : float, tuple or None, optional\n",
      "        The (winsorize_val[0])th lowest values are set to\n",
      "        the (winsorize_val[0])th percentile,\n",
      "        and the (winsorize_val[1])th highest values\n",
      "        are set to the (1 - winsorize_val[1])th percentile.\n",
      "        If one value passed, used for both ends.\n",
      "        If None, then no winsorization performed.\n",
      "        Note: Winsorizing will be performed after\n",
      "        filtering for outliers if values are passed for both.\n",
      "        (default = None)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    For loading a truly custom dataset, an advanced user can\n",
      "    load all the data themselves into a pandas DataFrame.\n",
      "    They will need to have the DataFrame indexed by 'src_subject_id'\n",
      "    e.g., data = data.set_index('src_subject_id')\n",
      "    and subject ids will need to be in the correct style...\n",
      "    but if they do all this, then they can just set\n",
      "    self.data = whatever_they_loaded_their_data_as\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 1.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip101_id', 'dataset_id', 'smri_visitid'] columns by default due to dataset type\n",
      "Dropped 0 columns, per drop_keys argument\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 522 rows for missing values\n",
      "Dropped rows with missing data\n",
      "Filtered data for outliers with value:  0.005\n",
      "Winsorized data with value:  0.01\n",
      "loaded shape:  (2099, 749)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 2099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.load_data(loc=test_data_loc1,\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.005, \n",
    "             winsorize_val=.01)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That ends up being a lot of data dropped just for dropping missing outliers... since we are not in low_memory_mode, we can just clear the data, and reload it. This time we will also load not just the first data loc, but the rest as well - and at the same time - but just providing the locations of both in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleared data.\n"
     ]
    }
   ],
   "source": [
    "ML.clear_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 1.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip101_id', 'dataset_id', 'smri_visitid'] columns by default due to dataset type\n",
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 2.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip201_id', 'dataset_id'] columns by default due to dataset type\n",
      "Dropped 0 columns, per drop_keys argument\n",
      "Dropped 10 cols for all missing values\n",
      "Dropped 1233 rows for missing values\n",
      "Dropped rows with missing data\n",
      "Filtered data for outliers with value:  0.0005\n",
      "Winsorized data with value:  0.001\n",
      "loaded shape:  (7303, 1186)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.load_data(loc=[test_data_loc1, test_data_loc2],\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.0005, \n",
    "             winsorize_val=.001)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These seem okay settings, we can load the next half of the data with these as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data for this expiriment should now be loaded. We can check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smri_thick_cortdesikan_banksstslh</th>\n",
       "      <th>smri_thick_cortdesikan_caudalanteriorcingulatelh</th>\n",
       "      <th>smri_thick_cortdesikan_caudalmiddlefrontallh</th>\n",
       "      <th>smri_thick_cortdesikan_cuneuslh</th>\n",
       "      <th>smri_thick_cortdesikan_entorhinallh</th>\n",
       "      <th>smri_thick_cortdesikan_fusiformlh</th>\n",
       "      <th>smri_thick_cortdesikan_inferiorparietallh</th>\n",
       "      <th>smri_thick_cortdesikan_inferiortemporallh</th>\n",
       "      <th>smri_thick_cortdesikan_isthmuscingulatelh</th>\n",
       "      <th>smri_thick_cortdesikan_lateraloccipitallh</th>\n",
       "      <th>...</th>\n",
       "      <th>smri_t2w_subcortaseg_hippocampusrh</th>\n",
       "      <th>smri_t2w_subcortaseg_amygdalarh</th>\n",
       "      <th>smri_t2w_subcortaseg_accumbensarearh</th>\n",
       "      <th>smri_t2w_subcortaseg_ventraldcrh</th>\n",
       "      <th>smri_t2w_subcortaseg_wmhypointensities</th>\n",
       "      <th>smri_t2w_subcortaseg_ccposterior</th>\n",
       "      <th>smri_t2w_subcortaseg_ccmidposterior</th>\n",
       "      <th>smri_t2w_subcortaseg_cccentral</th>\n",
       "      <th>smri_t2w_subcortaseg_ccmidanterior</th>\n",
       "      <th>smri_t2w_subcortaseg_ccanterior</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00R4TXET</th>\n",
       "      <td>2.817</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.012</td>\n",
       "      <td>2.155</td>\n",
       "      <td>3.115</td>\n",
       "      <td>2.810</td>\n",
       "      <td>2.854</td>\n",
       "      <td>3.147</td>\n",
       "      <td>2.629</td>\n",
       "      <td>2.348</td>\n",
       "      <td>...</td>\n",
       "      <td>166.147666</td>\n",
       "      <td>171.143448</td>\n",
       "      <td>152.634040</td>\n",
       "      <td>115.660336</td>\n",
       "      <td>152.816743</td>\n",
       "      <td>106.990743</td>\n",
       "      <td>120.449265</td>\n",
       "      <td>117.044747</td>\n",
       "      <td>112.399884</td>\n",
       "      <td>109.441508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00UMK5VC</th>\n",
       "      <td>2.685</td>\n",
       "      <td>2.666</td>\n",
       "      <td>2.895</td>\n",
       "      <td>1.987</td>\n",
       "      <td>3.107</td>\n",
       "      <td>2.947</td>\n",
       "      <td>2.887</td>\n",
       "      <td>3.256</td>\n",
       "      <td>2.434</td>\n",
       "      <td>2.350</td>\n",
       "      <td>...</td>\n",
       "      <td>170.350490</td>\n",
       "      <td>154.837096</td>\n",
       "      <td>133.076824</td>\n",
       "      <td>116.094815</td>\n",
       "      <td>147.913201</td>\n",
       "      <td>98.521998</td>\n",
       "      <td>131.900032</td>\n",
       "      <td>122.047120</td>\n",
       "      <td>102.673528</td>\n",
       "      <td>105.812915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV014RTM1V</th>\n",
       "      <td>2.783</td>\n",
       "      <td>2.999</td>\n",
       "      <td>2.956</td>\n",
       "      <td>2.030</td>\n",
       "      <td>3.170</td>\n",
       "      <td>2.940</td>\n",
       "      <td>2.718</td>\n",
       "      <td>3.014</td>\n",
       "      <td>2.444</td>\n",
       "      <td>2.266</td>\n",
       "      <td>...</td>\n",
       "      <td>166.764158</td>\n",
       "      <td>164.723606</td>\n",
       "      <td>163.940763</td>\n",
       "      <td>117.205626</td>\n",
       "      <td>211.238987</td>\n",
       "      <td>106.615366</td>\n",
       "      <td>125.595535</td>\n",
       "      <td>119.674263</td>\n",
       "      <td>116.918631</td>\n",
       "      <td>111.743396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV019DXLU4</th>\n",
       "      <td>2.944</td>\n",
       "      <td>3.078</td>\n",
       "      <td>2.931</td>\n",
       "      <td>2.166</td>\n",
       "      <td>3.459</td>\n",
       "      <td>2.980</td>\n",
       "      <td>2.785</td>\n",
       "      <td>3.080</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.360</td>\n",
       "      <td>...</td>\n",
       "      <td>159.890286</td>\n",
       "      <td>151.097159</td>\n",
       "      <td>145.289319</td>\n",
       "      <td>114.540321</td>\n",
       "      <td>140.991964</td>\n",
       "      <td>102.489477</td>\n",
       "      <td>110.442037</td>\n",
       "      <td>100.033514</td>\n",
       "      <td>102.737771</td>\n",
       "      <td>112.328037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV01ELX9L6</th>\n",
       "      <td>2.861</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.898</td>\n",
       "      <td>2.101</td>\n",
       "      <td>4.043</td>\n",
       "      <td>2.939</td>\n",
       "      <td>2.677</td>\n",
       "      <td>2.811</td>\n",
       "      <td>3.035</td>\n",
       "      <td>2.202</td>\n",
       "      <td>...</td>\n",
       "      <td>147.023012</td>\n",
       "      <td>148.368816</td>\n",
       "      <td>153.563722</td>\n",
       "      <td>112.275222</td>\n",
       "      <td>141.126298</td>\n",
       "      <td>102.607760</td>\n",
       "      <td>107.345429</td>\n",
       "      <td>103.728713</td>\n",
       "      <td>105.512885</td>\n",
       "      <td>106.459537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  smri_thick_cortdesikan_banksstslh  \\\n",
       "src_subject_id                                        \n",
       "NDAR_INV00R4TXET                              2.817   \n",
       "NDAR_INV00UMK5VC                              2.685   \n",
       "NDAR_INV014RTM1V                              2.783   \n",
       "NDAR_INV019DXLU4                              2.944   \n",
       "NDAR_INV01ELX9L6                              2.861   \n",
       "\n",
       "                  smri_thick_cortdesikan_caudalanteriorcingulatelh  \\\n",
       "src_subject_id                                                       \n",
       "NDAR_INV00R4TXET                                             3.372   \n",
       "NDAR_INV00UMK5VC                                             2.666   \n",
       "NDAR_INV014RTM1V                                             2.999   \n",
       "NDAR_INV019DXLU4                                             3.078   \n",
       "NDAR_INV01ELX9L6                                             2.400   \n",
       "\n",
       "                  smri_thick_cortdesikan_caudalmiddlefrontallh  \\\n",
       "src_subject_id                                                   \n",
       "NDAR_INV00R4TXET                                         3.012   \n",
       "NDAR_INV00UMK5VC                                         2.895   \n",
       "NDAR_INV014RTM1V                                         2.956   \n",
       "NDAR_INV019DXLU4                                         2.931   \n",
       "NDAR_INV01ELX9L6                                         2.898   \n",
       "\n",
       "                  smri_thick_cortdesikan_cuneuslh  \\\n",
       "src_subject_id                                      \n",
       "NDAR_INV00R4TXET                            2.155   \n",
       "NDAR_INV00UMK5VC                            1.987   \n",
       "NDAR_INV014RTM1V                            2.030   \n",
       "NDAR_INV019DXLU4                            2.166   \n",
       "NDAR_INV01ELX9L6                            2.101   \n",
       "\n",
       "                  smri_thick_cortdesikan_entorhinallh  \\\n",
       "src_subject_id                                          \n",
       "NDAR_INV00R4TXET                                3.115   \n",
       "NDAR_INV00UMK5VC                                3.107   \n",
       "NDAR_INV014RTM1V                                3.170   \n",
       "NDAR_INV019DXLU4                                3.459   \n",
       "NDAR_INV01ELX9L6                                4.043   \n",
       "\n",
       "                  smri_thick_cortdesikan_fusiformlh  \\\n",
       "src_subject_id                                        \n",
       "NDAR_INV00R4TXET                              2.810   \n",
       "NDAR_INV00UMK5VC                              2.947   \n",
       "NDAR_INV014RTM1V                              2.940   \n",
       "NDAR_INV019DXLU4                              2.980   \n",
       "NDAR_INV01ELX9L6                              2.939   \n",
       "\n",
       "                  smri_thick_cortdesikan_inferiorparietallh  \\\n",
       "src_subject_id                                                \n",
       "NDAR_INV00R4TXET                                      2.854   \n",
       "NDAR_INV00UMK5VC                                      2.887   \n",
       "NDAR_INV014RTM1V                                      2.718   \n",
       "NDAR_INV019DXLU4                                      2.785   \n",
       "NDAR_INV01ELX9L6                                      2.677   \n",
       "\n",
       "                  smri_thick_cortdesikan_inferiortemporallh  \\\n",
       "src_subject_id                                                \n",
       "NDAR_INV00R4TXET                                      3.147   \n",
       "NDAR_INV00UMK5VC                                      3.256   \n",
       "NDAR_INV014RTM1V                                      3.014   \n",
       "NDAR_INV019DXLU4                                      3.080   \n",
       "NDAR_INV01ELX9L6                                      2.811   \n",
       "\n",
       "                  smri_thick_cortdesikan_isthmuscingulatelh  \\\n",
       "src_subject_id                                                \n",
       "NDAR_INV00R4TXET                                      2.629   \n",
       "NDAR_INV00UMK5VC                                      2.434   \n",
       "NDAR_INV014RTM1V                                      2.444   \n",
       "NDAR_INV019DXLU4                                      2.677   \n",
       "NDAR_INV01ELX9L6                                      3.035   \n",
       "\n",
       "                  smri_thick_cortdesikan_lateraloccipitallh  ...  \\\n",
       "src_subject_id                                               ...   \n",
       "NDAR_INV00R4TXET                                      2.348  ...   \n",
       "NDAR_INV00UMK5VC                                      2.350  ...   \n",
       "NDAR_INV014RTM1V                                      2.266  ...   \n",
       "NDAR_INV019DXLU4                                      2.360  ...   \n",
       "NDAR_INV01ELX9L6                                      2.202  ...   \n",
       "\n",
       "                  smri_t2w_subcortaseg_hippocampusrh  \\\n",
       "src_subject_id                                         \n",
       "NDAR_INV00R4TXET                          166.147666   \n",
       "NDAR_INV00UMK5VC                          170.350490   \n",
       "NDAR_INV014RTM1V                          166.764158   \n",
       "NDAR_INV019DXLU4                          159.890286   \n",
       "NDAR_INV01ELX9L6                          147.023012   \n",
       "\n",
       "                  smri_t2w_subcortaseg_amygdalarh  \\\n",
       "src_subject_id                                      \n",
       "NDAR_INV00R4TXET                       171.143448   \n",
       "NDAR_INV00UMK5VC                       154.837096   \n",
       "NDAR_INV014RTM1V                       164.723606   \n",
       "NDAR_INV019DXLU4                       151.097159   \n",
       "NDAR_INV01ELX9L6                       148.368816   \n",
       "\n",
       "                  smri_t2w_subcortaseg_accumbensarearh  \\\n",
       "src_subject_id                                           \n",
       "NDAR_INV00R4TXET                            152.634040   \n",
       "NDAR_INV00UMK5VC                            133.076824   \n",
       "NDAR_INV014RTM1V                            163.940763   \n",
       "NDAR_INV019DXLU4                            145.289319   \n",
       "NDAR_INV01ELX9L6                            153.563722   \n",
       "\n",
       "                  smri_t2w_subcortaseg_ventraldcrh  \\\n",
       "src_subject_id                                       \n",
       "NDAR_INV00R4TXET                        115.660336   \n",
       "NDAR_INV00UMK5VC                        116.094815   \n",
       "NDAR_INV014RTM1V                        117.205626   \n",
       "NDAR_INV019DXLU4                        114.540321   \n",
       "NDAR_INV01ELX9L6                        112.275222   \n",
       "\n",
       "                  smri_t2w_subcortaseg_wmhypointensities  \\\n",
       "src_subject_id                                             \n",
       "NDAR_INV00R4TXET                              152.816743   \n",
       "NDAR_INV00UMK5VC                              147.913201   \n",
       "NDAR_INV014RTM1V                              211.238987   \n",
       "NDAR_INV019DXLU4                              140.991964   \n",
       "NDAR_INV01ELX9L6                              141.126298   \n",
       "\n",
       "                  smri_t2w_subcortaseg_ccposterior  \\\n",
       "src_subject_id                                       \n",
       "NDAR_INV00R4TXET                        106.990743   \n",
       "NDAR_INV00UMK5VC                         98.521998   \n",
       "NDAR_INV014RTM1V                        106.615366   \n",
       "NDAR_INV019DXLU4                        102.489477   \n",
       "NDAR_INV01ELX9L6                        102.607760   \n",
       "\n",
       "                  smri_t2w_subcortaseg_ccmidposterior  \\\n",
       "src_subject_id                                          \n",
       "NDAR_INV00R4TXET                           120.449265   \n",
       "NDAR_INV00UMK5VC                           131.900032   \n",
       "NDAR_INV014RTM1V                           125.595535   \n",
       "NDAR_INV019DXLU4                           110.442037   \n",
       "NDAR_INV01ELX9L6                           107.345429   \n",
       "\n",
       "                  smri_t2w_subcortaseg_cccentral  \\\n",
       "src_subject_id                                     \n",
       "NDAR_INV00R4TXET                      117.044747   \n",
       "NDAR_INV00UMK5VC                      122.047120   \n",
       "NDAR_INV014RTM1V                      119.674263   \n",
       "NDAR_INV019DXLU4                      100.033514   \n",
       "NDAR_INV01ELX9L6                      103.728713   \n",
       "\n",
       "                  smri_t2w_subcortaseg_ccmidanterior  \\\n",
       "src_subject_id                                         \n",
       "NDAR_INV00R4TXET                          112.399884   \n",
       "NDAR_INV00UMK5VC                          102.673528   \n",
       "NDAR_INV014RTM1V                          116.918631   \n",
       "NDAR_INV019DXLU4                          102.737771   \n",
       "NDAR_INV01ELX9L6                          105.512885   \n",
       "\n",
       "                  smri_t2w_subcortaseg_ccanterior  \n",
       "src_subject_id                                     \n",
       "NDAR_INV00R4TXET                       109.441508  \n",
       "NDAR_INV00UMK5VC                       105.812915  \n",
       "NDAR_INV014RTM1V                       111.743396  \n",
       "NDAR_INV019DXLU4                       112.328037  \n",
       "NDAR_INV01ELX9L6                       106.459537  \n",
       "\n",
       "[5 rows x 1186 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7303, 1186)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that data is loaded we still need to load targets, and can optionally load covars, strat and exclusions. Lets load our target first, and begin as before by checking out the loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_targets in module ABCD_ML._Data:\n",
      "\n",
      "load_targets(loc, col_name, data_type, filter_outlier_percent=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Loads in a set of subject ids and associated targets from a\n",
      "    2.0_ABCD_Data_Explorer release formatted csv.\n",
      "    See Notes for more info.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None\n",
      "        The location of the csv file to load targets load from.\n",
      "    \n",
      "    col_name : str\n",
      "        The name of the column to load.\n",
      "    \n",
      "    data_type : {'binary', 'categorical', 'ordinal', 'float'}\n",
      "        The data type of the targets column.\n",
      "        Shorthands for datatypes can be used as well\n",
      "    \n",
      "        - 'binary' or 'b' : Binary input\n",
      "        - 'categorical' or 'c' : Categorical input\n",
      "        - 'ordinal' or 'o' : Ordinal input\n",
      "        - 'float' or 'f' : Float numerical input\n",
      "    \n",
      "        Datatypes are explained further in Notes.\n",
      "    \n",
      "    filter_outlier_percent : float, tuple or None, optional\n",
      "        For float or ordinal datatypes only.\n",
      "        A percent of values to exclude from either end of the\n",
      "        target distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_outlier_percent` to None for no filtering.\n",
      "        (default = None).\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Targets can be either 'binary', 'categorical', 'ordinal' or 'float',\n",
      "    where ordinal and float are treated the same.\n",
      "    \n",
      "    For binary: targets are read in and label encoded to be 0 or 1,\n",
      "        Will also work if passed column of unique string also, e.g. 'M' and 'F'\n",
      "    \n",
      "    For categorical: targets are read in and by default one-hot encoded,\n",
      "        Note: This function is designed only to work with categorical targets\n",
      "        read in from one column!\n",
      "        Reading multiple targets from multiple places is not\n",
      "        supported as of now.\n",
      "    \n",
      "    For ordinal and float: targets are read in as a floating point number,\n",
      "        and optionally then filtered for outliers with the\n",
      "        filter_outlier_percent flag.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, lets just load in sex as our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Mental Health/ABCD Parent Demographics Survey.csv\n",
      "More than two unique score values found, filtered all but [1. 2.]\n",
      "Final shape:  (11866, 1)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.load_targets(loc=test_target_loc,\n",
    "                col_name='demo_sex_v2',\n",
    "                data_type='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the verbose print out above, you'll notice that it says \"More than two unique score values found,filtered all but [1. 2.]\" This is because by default when a binary datatype is passed, the dataloader needs to make sure it loads in only two unique values. To solve this when there exists outliers, like in this case, all but the top two unique values by count will be dropped. It will further show which values it has kept, in the case that an error was made, but here 1 and 2 are the correct sex values. If more than two values are desired, the categorical data type should be used.\n",
    "\n",
    "Let's look and see to make sure everything was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_subject_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0A4ZDYNL</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0BKE31EY</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0CBFTKR7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0CCEN5K2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0DC9BJZK</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  targets\n",
       "src_subject_id           \n",
       "NDAR_INV0A4ZDYNL        0\n",
       "NDAR_INV0BKE31EY        0\n",
       "NDAR_INV0CBFTKR7        0\n",
       "NDAR_INV0CCEN5K2        0\n",
       "NDAR_INV0DC9BJZK        0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look into adding covars next. Where co-variates arn't quite treated as typical co-variates, but are values we would like to be able to pass as additional input to the ML model if desired (and input that is treated in a special way, specifically covar input won't be scaled with any data scaler by default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_covars in module ABCD_ML._Data:\n",
      "\n",
      "load_covars(loc, col_names, data_types, dummy_code_categorical=True, filter_float_outlier_percent=None, standardize=True, normalize=False) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Load a covariate or covariates from a 2.0_ABCD_Data_Explorer\n",
      "    release formatted csv.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None\n",
      "        The location of the csv file to load co-variates load from.\n",
      "    \n",
      "    col_names : str or list\n",
      "        The name(s) of the column(s) to load.\n",
      "        Note: Must be in the same order as data types passed in.\n",
      "    \n",
      "    data_types : {'binary', 'categorical', 'ordinal', 'float'} or list of\n",
      "        The data types of the different columns to load,\n",
      "        in the same order as the column names passed in.\n",
      "        Shorthands for datatypes can be used as well\n",
      "    \n",
      "        - 'binary' or 'b' : Binary input\n",
      "        - 'categorical' or 'c' : Categorical input\n",
      "        - 'ordinal' or 'o' : Ordinal input\n",
      "        - 'float' or 'f' : Float numerical input\n",
      "    \n",
      "    dummy_code_categorical: bool, optional\n",
      "        If True, then categorical variables are dummy coded.\n",
      "        If False, then categorical variables are one-hot encoded.\n",
      "        (default = True)\n",
      "    \n",
      "    filter_float_outlier_percent, float, int, tuple or None, optional\n",
      "        For float datatypes only.\n",
      "        A percent of values to exclude from either end of the\n",
      "        targets distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_float_outlier_percent` to None for no filtering.\n",
      "        (default = None)\n",
      "    \n",
      "    standardize : bool, optional\n",
      "        If True, scales any float/ordinal covariate loaded to have\n",
      "        a mean of 0 and std of 1.\n",
      "        Note: Computed before normalization, both set to True.\n",
      "        (default = True)\n",
      "    \n",
      "    normalize : bool, optional\n",
      "        If True, scales any float/ordinal covariates loaded\n",
      "        to be between 0 and 1.\n",
      "        Note: Computed after standardization, if both set to True.\n",
      "        (default = False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_covars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading covariates from /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Mental Health/ABCD Parent Demographics Survey.csv\n",
      "load: demo_ed_v2\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.load_covars(loc=test_target_loc,\n",
    "               col_names = 'demo_ed_v2',\n",
    "               data_types = 'ordinal',\n",
    "               standardize = False,\n",
    "               normalize = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check to see it was loaded correctly (and normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_ed_v2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_subject_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0A4ZDYNL</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0BKE31EY</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0CBFTKR7</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0CCEN5K2</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV0DC9BJZK</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  demo_ed_v2\n",
       "src_subject_id              \n",
       "NDAR_INV0A4ZDYNL    0.416667\n",
       "NDAR_INV0BKE31EY    0.250000\n",
       "NDAR_INV0CBFTKR7    0.416667\n",
       "NDAR_INV0CCEN5K2    0.250000\n",
       "NDAR_INV0DC9BJZK    0.500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.covars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading stratification values (strat), these are the values that we can optionally define custom validation / split behavior on. Within this example, we are just going to make sure that all splits preserve subjects with the same family id within the same fold, so lets load family id - after looking as the help function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_strat in module ABCD_ML._Data:\n",
      "\n",
      "load_strat(loc, col_names) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Load stratification values from a 2.0_ABCD_Data_Explorer\n",
      "    release formatted csv.\n",
      "    See Notes for more details on what stratification values are.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None\n",
      "        The location of the csv file to load stratification vals from.\n",
      "    \n",
      "    col_names : str or list\n",
      "        The name(s) of the column(s) to load.\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Stratification values are categorical variables which are loaded for the\n",
      "    purpose of defining custom validation behavior.\n",
      "    \n",
      "    For example: Sex might be loaded here, and used later to ensure\n",
      "    that any validation splits retain the same distribution of each sex.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading stratification values from /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Other Non-Imaging/ABCD ACS Post Stratification Weights.csv\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7296\n",
      "\n",
      "Removing non overlapping + excluded subjects\n"
     ]
    }
   ],
   "source": [
    "ML.load_strat(loc=test_strat_loc,\n",
    "              col_names='rel_family_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_family_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_subject_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV9EVRB30H</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVDTHBFTNZ</th>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVLPY5VAXY</th>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVFL02R0H4</th>\n",
       "      <td>8956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INVP16EZY2C</th>\n",
       "      <td>3789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rel_family_id\n",
       "src_subject_id                 \n",
       "NDAR_INV9EVRB30H             86\n",
       "NDAR_INVDTHBFTNZ           1831\n",
       "NDAR_INVLPY5VAXY           1410\n",
       "NDAR_INVFL02R0H4           8956\n",
       "NDAR_INVP16EZY2C           3789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.strat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great looks good. Lastly, we can still optionally load in a list of subject ids to exclude - for whatever reason, from the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_exclusions in module ABCD_ML._Data:\n",
      "\n",
      "load_exclusions(loc=None, exclusions=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Loads in a set of excluded subjects,\n",
      "    from either a file or as directly passed in.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None, optional\n",
      "        Location of a file to load in excluded subjects from.\n",
      "        The file should be formatted as one subject per line.\n",
      "        (default = None)\n",
      "    \n",
      "    exclusions : list, set, array-like or None, optional\n",
      "        An explicit list of subjects to add to exclusions.\n",
      "        (default = None)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    If default subject id behavior is set to False,\n",
      "    reading subjects from a exclusion loc might not\n",
      "    function as expected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_exclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total excluded subjects:  1137\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 6622\n",
      "\n",
      "Removing non overlapping + excluded subjects\n"
     ]
    }
   ],
   "source": [
    "ML.load_exclusions(loc=test_exclusion_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have our data, targets, covars, strat and exclusions loaded (Noting that the minimum requiriments for running an ML expiriment are just data or covars and targets, the rest being optional). The actual length of the script is also not as terrible as it seems, and once loading behavior is confirmed, verbose can even be turned off. To show this, we can re-load everything as above with verbose off. (Commented out, but you get the idea~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML = ABCD_ML.ABCD_ML(n_jobs = 4, verbose = False) # Reloading the ML object itself to reset everything.\n",
    "\n",
    "#ML.load_name_map(loc = test_mapping_loc,\n",
    "#                 source_name_col = \"NDAR name\",\n",
    "#                 target_name_col = \"REDCap name/NDA alias\")\n",
    "\n",
    "#ML.load_data(loc=[test_data_loc1, test_data_loc2],\n",
    "#             dataset_type='explorer',\n",
    "#             filter_outlier_percent=.0005, \n",
    "#             winsorize_val=.01)\n",
    "\n",
    "#ML.load_targets(loc=test_target_loc,\n",
    "#                col_name='demo_sex_v2',\n",
    "#                data_type='b')\n",
    "\n",
    "#ML.load_covars(loc=test_target_loc,\n",
    "#               col_names = 'demo_ed_v2',\n",
    "#               data_types = 'ordinal',\n",
    "#               standardize = False,\n",
    "#               normalize = True)\n",
    "\n",
    "#ML.load_strat(loc=test_strat_loc,\n",
    "#              col_names='rel_family_id')\n",
    "\n",
    "#ML.load_exclusions(loc=test_exclusion_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue. We will turn verbose back on, and then move onto defining our validation stratagy (which is again optional, but as stated before for this example we are going to preserve like family ids within the same folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method define_validation_strategy in module ABCD_ML.ABCD_ML:\n",
      "\n",
      "define_validation_strategy(groups=None, stratify=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Define a validation stratagy to be used during different train/test splits,\n",
      "    in addition to model selection and model hyperparameter CV.\n",
      "    See Notes for more info.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    groups : str, list or None, optional\n",
      "        In the case of str input, will assume the str to refer\n",
      "        to a column key within the loaded strat data,\n",
      "        and will assign it as a value to preserve groups by\n",
      "        during any train/test or K-fold splits.\n",
      "        If a list is passed, then each element should be a str,\n",
      "        and they will be combined into all unique\n",
      "        combinations of the elements of the list.\n",
      "        (default = None)\n",
      "    \n",
      "    stratify : str, list or None, optional\n",
      "        In the case of str input, will assume the str to refer\n",
      "        to a column key within the loaded strat data,\n",
      "        and will assign it as a value to preserve\n",
      "        distribution of groups by during any train/test or K-fold splits.\n",
      "        'targets' or whatever the value of self.original_targets_key,\n",
      "        can also be passed in the case of binary/categorical problems.\n",
      "        If a list is passed, then each element should be a str,\n",
      "        and they will be combined into all unique combinations of\n",
      "        the elements of the list.\n",
      "        (default = None)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Validation stratagy choices are explained in more detail:\n",
      "    \n",
      "        Random: Just make splits randomly\n",
      "    \n",
      "        Group Preserving: Make splits that ensure subjects that are\n",
      "            part of specific group are all within the same fold\n",
      "            e.g., split by family, so that people with the same family id\n",
      "            are always a part of the same fold.\n",
      "    \n",
      "        Stratifying: Make splits such that the distribution of a given\n",
      "            group is as equally split between two folds as possible,\n",
      "            so simmilar to matched halves or\n",
      "            e.g., in a binary or categorical predictive context,\n",
      "            splits could be done to ensure roughly equal distribution\n",
      "            of the dependent class.\n",
      "    \n",
      "    For now, it is possible to define only one overarching stratagy\n",
      "    (One could imagine combining group preserving splits\n",
      "    while also trying to stratify for class,\n",
      "    but the logistics become more complicated).\n",
      "    Though, within one strategy it is certainly possible to\n",
      "    provide multiple values\n",
      "    e.g., for stratification you can stratify by target\n",
      "    (the dependent variable to be predicted)\n",
      "    as well as say sex, though with addition of unique value,\n",
      "    the size of the smallest unique group decreases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.define_validation_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for group preserving behavior we are interested in supplying an argument for groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV defined with group preserving behavior, over 5990 unique values.\n"
     ]
    }
   ],
   "source": [
    "ML.verbose = True\n",
    "ML.define_validation_strategy(groups='rel_family_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when it says over 9985 unique values, this is just over all of the loaded values within ML.strat. In practice, splits will take place over only the overlap of subjects minus loaded exclusions, the above is just saying there are 9985 unique values in just strat - not the overlap.\n",
    "\n",
    "Lastly before we get to modelling, we want to define a global train-test split, so that we can perform model exploration, and parameter tuning ect... on a training set, and leave a left-out testing set to eventually test with out final selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method train_test_split in module ABCD_ML.ABCD_ML:\n",
      "\n",
      "train_test_split(test_size=None, test_loc=None, test_subjects=None, random_state=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Define the overarching train / test split, highly reccomended.\n",
      "    \n",
      "    test_size: float, int or None, optional\n",
      "        If float, should be between 0.0 and 1.0 and represent\n",
      "        the proportion of the dataset to be included in the test split.\n",
      "        If int, represents the absolute number (or target number) to\n",
      "        include in the testing group.\n",
      "        Set to None if using test_loc or test_subjects.\n",
      "        (default = None)\n",
      "    \n",
      "    test_loc : str, Path or None, optional\n",
      "        Location of a file to load in test subjects from.\n",
      "        The file should be formatted as one subject per line.\n",
      "        (default = None)\n",
      "    \n",
      "    test_subjects : list, set, array-like or None, optional\n",
      "        An explicit list of subjects to constitute the testing set\n",
      "        (default=None)\n",
      "    \n",
      "    random_state : int or None, optional\n",
      "        If using test_size, then can optionally provide a random state, in\n",
      "        order to be able to recreate an exact test set.\n",
      "        (default = None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data for modeling loaded shape: (6622, 1188)\n",
      "Performed train/test split, train size: 4960 test size:  1662\n"
     ]
    }
   ],
   "source": [
    "ML.train_test_split(test_size=.25, #Let be somewhat conservative, and use a size of .25\n",
    "                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - and because we set the validation stratagy to preserve family structure within the folds, we know that no family id is in both the train and test set - for the paranoid we can make sure of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique family ids in train:  4492\n",
      "Unique family ids in test:  1498\n",
      "Overlap :  0\n"
     ]
    }
   ],
   "source": [
    "train_ids = set(ML.strat['rel_family_id'].loc[ML.train_subjects])\n",
    "test_ids = set(ML.strat['rel_family_id'].loc[ML.test_subjects])\n",
    "\n",
    "print('Unique family ids in train: ', len(train_ids))\n",
    "print('Unique family ids in test: ', len(test_ids))\n",
    "print('Overlap : ', len(train_ids.intersection(test_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to modeling.\n",
    "\n",
    "The main function we use here is Evaluate, we can look at its docstring, but from a very high level, this is the function we use to test different expirimental setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Evaluate in module ABCD_ML._ML:\n",
      "\n",
      "Evaluate(model_type, problem_type='default', data_scaler='default', n_splits='default', n_repeats='default', int_cv='default', metric='default', class_weight='default', n_jobs='default', n_iter='default', random_state='default', extra_params='default') method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Class method to be called during the model selection phase.\n",
      "    Used to evaluated different combination of models and scaling, ect...\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    model_type : str or list of str,\n",
      "        Each string refers to a type of model to train.\n",
      "        If a list of strings is passed then an ensemble model\n",
      "        will be created over all individual models.\n",
      "        For a full list of supported options call:\n",
      "        self.show_model_types(), with optional problem type parameter.\n",
      "    \n",
      "    problem_type : {'regression', 'binary', 'categorical', 'default'}, optional\n",
      "    \n",
      "        - 'regression' : For ML on float or ordinal target data\n",
      "        - 'binary' : For ML on binary target data\n",
      "        - 'categorical' : For ML on categorical target data,\n",
      "                          as either multilabel or multiclass.\n",
      "        - 'default' : Use the name problem type within self.default_ML_params.\n",
      "    \n",
      "        (default = 'default')\n",
      "    \n",
      "    data_scaler : str, optional\n",
      "        `data_scaler` refers to the type of scaling to apply\n",
      "        to the saved data during model evaluation.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        For a full list of supported options call:\n",
      "        self.show_data_scalers()\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_splits : int or 'default', optional\n",
      "        evaluate_model performs a repeated k-fold model evaluation,\n",
      "        `n_splits` refers to the k. E.g., if set to 3, then a 3-fold\n",
      "        repeated CV will be performed. This parameter is typically\n",
      "        chosen as a trade off between bias and variance, in addition to\n",
      "        as a function of sample size.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_repeats : int or 'default', optional\n",
      "        evaluate_model performs a repeated k-fold model evaluation,\n",
      "        `n_repeats` refers to the number of times to repeat the\n",
      "        k-fold CV. This parameter is typical chosen as a balance between\n",
      "        run time, and accuratly accessing model performance.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 2)\n",
      "    \n",
      "    int_cv : int or 'default', optional\n",
      "        The number of internal folds to use during\n",
      "        model k-fold parameter selection, if the chosen model requires\n",
      "        parameter selection. A value greater\n",
      "        then 2 must be passed.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    metric : str, optional\n",
      "        Indicator for which metric to use for calculating\n",
      "        score and during model parameter selection.\n",
      "        If `metric` left as 'default', then the default metric/scorer\n",
      "        for that problem types will be used.\n",
      "        'regression'  : 'r2',\n",
      "        'binary'      : 'roc',\n",
      "        'categorical' : 'weighted roc auc'\n",
      "        Note, some metrics are only avaliable for certain problem types.\n",
      "        For a full list of supported metrics call:\n",
      "        self.show_metrics, with optional problem type parameter.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    class weight : {dict, 'balanced', None, 'default'}, optional\n",
      "        Only used for binary and categorical problem types.\n",
      "        Follows sklearn api class weight behavior. Typically, either use\n",
      "        'balanced' in the case of class distribution imbalance, or None.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_jobs : int or 'default', optional\n",
      "        The number of jobs to use (if avaliable) during training ML models.\n",
      "        This should be the number of procesors avaliable, if wanting to run\n",
      "        as fast as possible.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_iter : int or 'default', optional\n",
      "        The number of random search parameters to try, used\n",
      "        only if using random search.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    random_state : int, RandomState instance, None or 'default', optional\n",
      "        Random state, either as int for a specific seed, or if None then\n",
      "        the random seed is set by np.random.\n",
      "        If 'default', use the saved value within self,\n",
      "        (defined when initing ABCD_ML class) ^,\n",
      "        Or a different ML params random state is used, if defined when\n",
      "        calling set default ML params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    extra_params : dict or 'default', optional\n",
      "        Any extra params being passed. Typically, extra params are\n",
      "        added when the user wants to provide a specific model/classifier,\n",
      "        or data scaler, with updated (or new) parameters.\n",
      "        These can be supplied by creating another dict within extra_params.\n",
      "        E.g., extra_params[model_name] = {'model_param' : new_value}\n",
      "        Where model param is a valid argument for that model, and model_name in\n",
      "        this case is the str indicator passed to model_type.\n",
      "        If 'default', use the saved value within self.default_ML_params.\n",
      "        (default = 'default')\n",
      "    \n",
      "    Returns\n",
      "    ----------\n",
      "    list of floats\n",
      "        The raw score as computed for each fold within each repeat,\n",
      "        e.g., list will have a length of `n_repeats` * `n_splits`\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Prints by default the following,\n",
      "    \n",
      "    float\n",
      "        The mean macro score (as set by input metric) across each\n",
      "        repeated K-fold.\n",
      "    \n",
      "    float\n",
      "        The standard deviation of the macro score (as set by input metric)\n",
      "        across each repeated K-fold.\n",
      "    \n",
      "    float\n",
      "        The mean micro score (as set by input metric) across each\n",
      "        fold with the repeated K-fold.\n",
      "    \n",
      "    float\n",
      "        The standard deviation of the micro score (as set by input metric)\n",
      "        across each fold with the repeated K-fold.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check what different model types we have avaliable for binary first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: gs and rs are  Grid Search and Random Search\n",
      "Models with gs or rs will have their hyper-parameters tuned accordingly.\n",
      "\n",
      "Problem Type: binary\n",
      "----------------------\n",
      "Avaliable models: \n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  gaussian nb\n",
      "Model object:  <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  lgbm classifier\n",
      "Model object:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "\n",
      "Model str indicator:  lgbm classifier rs\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  logistic\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "\n",
      "Model str indicator:  logistic cv\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "\n",
      "Model str indicator:  rf classifier\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  rf classifier rs\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.show_model_types(problem_type='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set some default ML params for some of the settings that we will be keeping the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method set_default_ML_params in module ABCD_ML._ML:\n",
      "\n",
      "set_default_ML_params(problem_type='default', metric='default', data_scaler='default', n_splits='default', n_repeats='default', int_cv='default', class_weight='default', n_jobs='default', n_iter='default', random_state='default', extra_params='default') method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Sets the self.default_ML_params dictionary with user passed or default\n",
      "    values. In general, if any argument is left as 'default' and it has\n",
      "    not been previously defined, it will be set to a default value,\n",
      "    sometimes passed on other values.\n",
      "    See notes for rationale behind default ML params.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    problem_type : {'regression', 'binary', 'categorical', 'default'}, optional\n",
      "    \n",
      "        - 'regression' : For ML on float or ordinal target data\n",
      "        - 'binary' : For ML on binary target data\n",
      "        - 'categorical' : For ML on categorical target data,\n",
      "                          as either multilabel or multiclass.\n",
      "        - 'default' : Use 'regression' if nothing else already defined\n",
      "    \n",
      "        (default = 'default')\n",
      "    \n",
      "    metric : str, optional\n",
      "        Indicator for which metric to use for calculating\n",
      "        score and during model parameter selection.\n",
      "        If `metric` left as 'default', then the default metric/scorer\n",
      "        for that problem types will be used.\n",
      "        'regression'  : 'r2',\n",
      "        'binary'      : 'roc',\n",
      "        'categorical' : 'weighted roc auc'\n",
      "        Note, some metrics are only avaliable for certain problem types.\n",
      "        For a full list of supported metrics call:\n",
      "        self.show_metrics, with optional problem type parameter.\n",
      "        If 'default', and not already defined, set to default\n",
      "        metric for the problem type.\n",
      "        (default = 'default')\n",
      "    \n",
      "    data_scaler : str, optional\n",
      "        `data_scaler` refers to the type of scaling to apply\n",
      "        to the saved data during model evaluation.\n",
      "        If 'default', and not already defined, set to 'standard'\n",
      "        For a full list of supported options call:\n",
      "        self.show_data_scalers()\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_splits : int or 'default', optional\n",
      "        evaluate_model performs a repeated k-fold model evaluation,\n",
      "        `n_splits` refers to the k. E.g., if set to 3, then a 3-fold\n",
      "        repeated CV will be performed. This parameter is typically\n",
      "        chosen as a trade off between bias and variance, in addition to\n",
      "        as a function of sample size.\n",
      "        If 'default', and not already defined, set to 3\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_repeats : int or 'default', optional\n",
      "        evaluate_model performs a repeated k-fold model evaluation,\n",
      "        `n_repeats` refers to the number of times to repeat the\n",
      "        k-fold CV. This parameter is typical chosen as a balance between\n",
      "        run time, and accuratly accessing model performance.\n",
      "        If 'default', and not already defined, set to 2\n",
      "        (default = 2)\n",
      "    \n",
      "    int_cv : int or 'default', optional\n",
      "        The number of internal folds to use during\n",
      "        model k-fold parameter selection, if the chosen model requires\n",
      "        parameter selection. A value greater\n",
      "        then 2 must be passed.\n",
      "        If 'default', and not already defined, set to 3\n",
      "        (default = 'default')\n",
      "    \n",
      "    class weight : {dict, 'balanced', None, 'default'}, optional\n",
      "        Only used for binary and categorical problem types.\n",
      "        Follows sklearn api class weight behavior. Typically, either use\n",
      "        'balanced' in the case of class distribution imbalance, or None.\n",
      "        If 'default', and not already defined, set to 'balanced'\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_jobs : int or 'default', optional\n",
      "        The number of jobs to use (if avaliable) during training ML models.\n",
      "        This should be the number of procesors avaliable, if wanting to run\n",
      "        as fast as possible.\n",
      "        if 'default', and not already defined, set to 1.\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_iter : int or 'default', optional\n",
      "        The number of random search parameters to try, used\n",
      "        only if using random search.\n",
      "        if 'default', and not already defined, set to 10.\n",
      "        (default = 'default')\n",
      "    \n",
      "    random_state : int, RandomState instance, None or 'default', optional\n",
      "        Random state, either as int for a specific seed, or if None then\n",
      "        the random seed is set by np.random.\n",
      "        If 'default', use the saved value within self,\n",
      "        (defined when initing ABCD_ML class) ^,\n",
      "        Or can define a different random state for use in ML.\n",
      "        (default = 'default')\n",
      "    \n",
      "    extra_params : dict or 'default', optional\n",
      "        Any extra params being passed. Typically, extra params are\n",
      "        added when the user wants to provide a specific model/classifier,\n",
      "        or data scaler, with updated (or new) parameters.\n",
      "        These can be supplied by creating another dict within extra_params.\n",
      "        E.g., extra_params[model_name] = {'model_param' : new_value}\n",
      "        Where model param is a valid argument for that model, and model_name in\n",
      "        this case is the str indicator passed to model_type.\n",
      "        If 'default', and not already defined, set to empty dict.\n",
      "        (default = 'default')\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    `default_ML_params` are used in the case where the same settings\n",
      "    are being set over and over. For example, if only exploring a binary\n",
      "    problem_type, the default type should be set to 'binary',\n",
      "    and then the user won't have to pass it as an argument everytime they call\n",
      "    Evaluate().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.set_default_ML_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are mostly the same for setting default params as they are passed to Evaluate or Test. Importantly, by defining defaults, we define the value to be used if no value is passed to a given argument in Evaluate or Test.\n",
    "Lets set some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No default random state passed, using class random state value of None\n",
      "No default extra params passed, set to empty dict\n",
      "Default params set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.set_default_ML_params(problem_type = 'binary',\n",
    "                         metric = 'macro roc auc',\n",
    "                         data_scaler = 'standard',\n",
    "                         n_splits = 3,\n",
    "                         n_repeats = 2,\n",
    "                         int_cv = 3,\n",
    "                         class_weight = 'balanced',\n",
    "                         n_jobs = 8,\n",
    "                         n_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have default parameters set up, we can run an evaluation with the random forest classifier as just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = rf classifier\n",
      "problem_type = binary\n",
      "metric = macro roc auc\n",
      "data_scaler = standard\n",
      "n_splits = 3\n",
      "n_repeats = 2\n",
      "int_cv = 3\n",
      "class_weight = balanced\n",
      "n_jobs = 8\n",
      "n_iter = 20\n",
      "random_state = None\n",
      "extra_params = {}\n",
      "\n",
      "Macro mean score:  0.8124107227126789\n",
      "Macro std in score:  0.0005335189642660665\n",
      "Micro mean score:  0.8124107227126788\n",
      "Micro std in score:  0.0080002119314011\n"
     ]
    }
   ],
   "source": [
    "scores = ML.Evaluate(model_type='rf classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = logistic\n",
      "problem_type = binary\n",
      "metric = macro roc auc\n",
      "data_scaler = standard\n",
      "n_splits = 3\n",
      "n_repeats = 2\n",
      "int_cv = 3\n",
      "class_weight = balanced\n",
      "n_jobs = 8\n",
      "n_iter = 20\n",
      "random_state = None\n",
      "extra_params = {}\n",
      "\n",
      "Macro mean score:  0.9239552196541189\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.9239552196541189\n",
      "Micro std in score:  0.011150051065993628\n"
     ]
    }
   ],
   "source": [
    "scores = ML.Evaluate(model_type='logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the simple logistic regression does a lot better then just a single random forest. Let's compare also with random forest with hyperparameter tuning via random search, let also use extra params to show how we can override the default value of verbose within the sklearn random search object, and see the progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will take a while, feel free to comment it out or just skip it\n",
    "#extra_params = {'rf classifier rs': {'verbose': 1}}\n",
    "#scores = ML.Evaluate(model_type='rf classifier rs', extra_params=extra_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay what about just using logistic CV instead of straight logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = logistic cv\n",
      "problem_type = binary\n",
      "metric = macro roc auc\n",
      "data_scaler = standard\n",
      "n_splits = 3\n",
      "n_repeats = 2\n",
      "int_cv = 3\n",
      "class_weight = balanced\n",
      "n_jobs = 8\n",
      "n_iter = 20\n",
      "random_state = None\n",
      "extra_params = {}\n",
      "\n",
      "Macro mean score:  0.9383524635356503\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.9383524635356503\n",
      "Micro std in score:  0.009194294299791721\n"
     ]
    }
   ],
   "source": [
    "scores = ML.Evaluate(model_type='logistic cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9488978903824488,\n",
       " 0.9264920304027544,\n",
       " 0.9396674698217475,\n",
       " 0.9488978903824488,\n",
       " 0.9264920304027544,\n",
       " 0.9396674698217475]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.9488978903824488,\n",
    " 0.9264920304027544,\n",
    " 0.9396674698217475,\n",
    " 0.9488978903824488,\n",
    " 0.9264920304027544,\n",
    " 0.9396674698217475]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
